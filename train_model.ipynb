{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import argparse, os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from model_load import *\n",
    "from dataloader import *\n",
    "from torchsummary import summary as summary_\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b3071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8913c102",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cifar100_train, cifar100_valid = cifar100(224, 32, 4)\n",
    "cifar10_train, cifar10_valid = cifar10(224, 128, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # true_dist = pred.data.clone()\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticLoss(nn.Module):\n",
    "    def __init__(self, n_class=10, s=30.0, m=0.2,std=0.1,plus=False):\n",
    "        super(ElasticLoss, self).__init__()\n",
    "        #self.in_features = in_features\n",
    "        self.n_class = n_class\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = torch.nn.Parameter(torch.FloatTensor(n_class, 192), requires_grad=True)\n",
    "        nn.init.xavier_normal_(self.weight, gain=1)\n",
    "        self.std=std\n",
    "        self.plus=plus\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, embeddings, label):\n",
    "        cos_theta = F.linear(F.normalize(embeddings), F.normalize(self.weight))\n",
    "        cos_theta = cos_theta.clamp(-1, 1)  # for numerical stability\n",
    "        index = torch.where(label != -1)[0]\n",
    "        m_hot = torch.zeros(index.size()[0], cos_theta.size()[1], device=cos_theta.device)\n",
    "        margin = torch.normal(mean=self.m, std=self.std, size=label[index, None].size(), device=cos_theta.device).clamp(self.m-self.std, self.m+self.std) # Fast converge \n",
    "        if self.plus:\n",
    "            with torch.no_grad():\n",
    "                distmat = cos_theta[index, label.view(-1)].detach().clone()\n",
    "                _, idicate_cosie = torch.sort(distmat, dim=0, descending=True)\n",
    "                margin, _ = torch.sort(margin, dim=0)\n",
    "            m_hot.scatter_(1, label[index, None], margin[idicate_cosie])\n",
    "        else:\n",
    "            m_hot.scatter_(1, label[index, None], margin)\n",
    "        cos_theta.acos_()\n",
    "        cos_theta[index] += m_hot\n",
    "        cos_theta.cos_().mul_(self.s)\n",
    "        \n",
    "        loss = self.ce(cos_theta, label)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4768953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, save_name, train_loader, valid_loader, epochs, loss_n, lr):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "    \n",
    "    if loss_n == 'ce':\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "    elif loss_n == 'ls':\n",
    "        criterion = LabelSmoothingLoss(10, smoothing=0.1).to(device)\n",
    "    else:\n",
    "        criterion = ElasticLoss(10).to(device)\n",
    "        \n",
    "    model.to(device)   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=1)\n",
    "    best_loss = 10.0\n",
    "    best_acc = 0.0\n",
    "    v_loss = 0\n",
    "    tt = []\n",
    "    vv = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        scheduler.step(v_loss)\n",
    "        running_loss = 0.0\n",
    "        for img, label in tqdm(train_loader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_pred = model(img)\n",
    "            loss = criterion(y_pred, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            p_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'epoch:{epoch+1}, lr:{p_lr:.6f},Train loss:{running_loss/len(train_loader): .4f}')\n",
    "                \n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        correct = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for img, label in valid_loader:\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                y_pred = model(img)\n",
    "                valid_loss += criterion(y_pred, label)\n",
    "                pred = y_pred.argmax(dim = 1, keepdim = True)\n",
    "                correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "            valid_acc = 100*correct/len(valid_loader.dataset)\n",
    "            v_loss = valid_loss/len(valid_loader)\n",
    "            print(f'valid_loss : {v_loss:.4f}, ACC : {valid_acc:.4f}')\n",
    "            \n",
    "            if loss_n in ['ce', 'ls']:\n",
    "                if best_acc < valid_acc:\n",
    "                    best_acc = valid_acc\n",
    "                    torch.save(model.state_dict(), os.path.join('.', save_name+'.pth'))\n",
    "                    print('Model saved')\n",
    "            else:\n",
    "                if best_loss > v_loss:\n",
    "                    best_loss = v_loss\n",
    "                    torch.save(model.state_dict(), os.path.join('.', save_name+'.pth'))\n",
    "                    print('Model saved')\n",
    "                    \n",
    "        tt.append(running_loss/len(train_loader))\n",
    "        vv.append(v_loss)\n",
    "    return tt, vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3547e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_load('efficientnet_b0', False, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_(model.cuda(), (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881cfbd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loss_ce, valid_loss_ce = train(model, 'efficientnet_b0', cifar10_train, cifar10_valid, 50, 'ce', 1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
