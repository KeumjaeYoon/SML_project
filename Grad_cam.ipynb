{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e420150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb0d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutputs_resnet():\n",
    "    def __init__(self, model, target_layers, target_sub_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.target_sub_layers = target_sub_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.gradients = []\n",
    "        for name, module in self.model.named_children(): # 모든 layer에 대해서 직접 접근\n",
    "            x = module(x)\n",
    "            if name== 'avgpool': # avgpool이후 fully connect하기 전 data shape을 flatten시킴\n",
    "                x = torch.flatten(x,1)\n",
    "            if name in self.target_layers: # target_layer라면 해당 layer에서의 gradient를 저장\n",
    "                for sub_name, sub_module in module[len(module)-1].named_children():\n",
    "                    if sub_name in self.target_sub_layers:\n",
    "                        x.register_hook(self.save_gradient) #\n",
    "                        target_feature_maps = x # x's shape = 512X14X14(C,W,H) feature map\n",
    "        return target_feature_maps, x # target_activation : target_activation_layer's feature maps // output : classification ( ImageNet's classes : 1000 )\n",
    "\n",
    "\n",
    "class GradCam_resnet:\n",
    "    def __init__(self, model, target_layer_names, target_sub_layer_names, use_cuda):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:  # GPU일 경우 model을 cuda로 설정\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        self.extractor = ModelOutputs_resnet(self.model, target_layer_names,target_sub_layer_names)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "    def __call__(self, input, index=None):\n",
    "\n",
    "        if self.cuda:  # GPU일 경우 input을 cuda로 변환하여 전달\n",
    "            features, output = self.extractor(input.cuda())\n",
    "        else:\n",
    "            features, output = self.extractor(input)\n",
    "\n",
    "        probs,idx = 0, 0\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy())  # index = 정답이라고 추측한 class index\n",
    "            h_x = F.softmax(output,dim=1).data.squeeze()\n",
    "            probs, idx = h_x.sort(0,True)\n",
    "\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][index] = 1  # 정답이라고 생각하는 class의 index 리스트 위치의 값만 1로\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)  # numpy배열을 tensor로 변환\n",
    "        # requires_grad == True 텐서의 모든 연산에 대하여 추적\n",
    "        if self.cuda:\n",
    "            one_hot = torch.sum(one_hot.cuda() * output)\n",
    "        else:\n",
    "            one_hot = torch.sum(one_hot * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "\n",
    "        target = features  # A^k\n",
    "\n",
    "        target_cam = target.cpu().data.numpy()\n",
    "        bz, nc, h,w = target_cam.shape\n",
    "\n",
    "        target = target.cpu().data.numpy()[0, :]\n",
    "\n",
    "        params = list(self.model.parameters())\n",
    "\n",
    "        weight_softmax = np.squeeze(params[-2].data.cpu().numpy())\n",
    "\n",
    "        cam = weight_softmax[index].dot(target_cam.reshape((nc,h*w)))\n",
    "        cam = cam.reshape(h,w)\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cv2.resize(cam, (224, 224))  # 224X224크기로 변환\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "\n",
    "\n",
    "        weights = np.mean(grads_val, axis=(2, 3))[0, :]  # 논문에서의 global average pooling 식에 해당하는 부분\n",
    "        grad_cam = np.zeros(target.shape[1:], dtype=np.float32)  # 14X14\n",
    "\n",
    "        for i, w in enumerate(weights): # calcul grad_cam\n",
    "            grad_cam += w * target[i, :, :]  # linear combination L^c_{Grad-CAM}에 해당하는 식에서 ReLU를 제외한 식\n",
    "\n",
    "        grad_cam = np.maximum(grad_cam, 0)  # 0보다 작은 값을 제거\n",
    "        grad_cam = cv2.resize(grad_cam, (224, 224))  # 224X224크기로 변환\n",
    "        grad_cam = grad_cam - np.min(grad_cam)  #\n",
    "        grad_cam = grad_cam / np.max(grad_cam)  # 위의 것과 해당 줄의 것은 0~1사이의 값으로 정규화하기 위한 정리\n",
    "        return grad_cam, cam, index, probs, idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
